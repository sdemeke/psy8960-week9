{"kind": "Listing", "data": {"after": "t3_11w8jnl", "dist": 25, "modhash": "", "geo_filter": null, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "", "author_fullname": "t2_2hf9citq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do weeks 1-5 take up lesser space than other groups of 5?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11yjjum", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AGEkx69fPZyVDnXCubl4xT2ReQ6TsHgiHxtSu5-4lmk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1679492658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3g20s501oapa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3g20s501oapa1.png?auto=webp&amp;v=enabled&amp;s=fc7abfa92d15eea724400c2306b8a15107feebea", "width": 2096, "height": 2098}, "resolutions": [{"url": "https://preview.redd.it/3g20s501oapa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f37a4fb9e36ac4f7a1cfeefe1a77de774d02de4", "width": 108, "height": 108}, {"url": "https://preview.redd.it/3g20s501oapa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a61e92b7b837b8b9ecf325c1c84a53fe05aa820d", "width": 216, "height": 216}, {"url": "https://preview.redd.it/3g20s501oapa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c56c900190c8bc818e24e91dfb91098ecb2ef78c", "width": 320, "height": 320}, {"url": "https://preview.redd.it/3g20s501oapa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c967ecb8558fadeb1c42f7730e5933fa54c06a7", "width": 640, "height": 640}, {"url": "https://preview.redd.it/3g20s501oapa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e94f94b6511164ed78538444e9739a6fdf4cb2c", "width": 960, "height": 960}, {"url": "https://preview.redd.it/3g20s501oapa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0ac58a227125efef1b525559f203be987c1b7dc", "width": 1080, "height": 1081}], "variants": {}, "id": "zElAOq6o7oqWL7hy_sfe7lTl-wC8CdA8h-__vR-54Io"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11yjjum", "is_robot_indexable": true, "report_reasons": null, "author": "ariathriven", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11yjjum/why_do_weeks_15_take_up_lesser_space_than_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3g20s501oapa1.png", "subreddit_subscribers": 71012, "created_utc": 1679492658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "I've been messing around with Quarto reports and using flextable package to format some tables I queried. I don't like the way they are coming out and tinkering around with them has left still in mystery. What I'd really like is if my headers were wrapped but my a data was a single row if that makes sense..? It seems like that is difficult to achieve. Now if I have a table with 4 columns and I have a table with 7 columns, I still would like to take up the allotted page width but still following that column and cell format I mentioned above.\n\n&amp;#x200B;\n\nWhat are you guys go to secret for achieving  perfect  tables in a Quarto Word Report?", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you get perfect tables for Microsoft Word using Quarto?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ywud9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679519525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been messing around with Quarto reports and using flextable package to format some tables I queried. I don&amp;#39;t like the way they are coming out and tinkering around with them has left still in mystery. What I&amp;#39;d really like is if my headers were wrapped but my a data was a single row if that makes sense..? It seems like that is difficult to achieve. Now if I have a table with 4 columns and I have a table with 7 columns, I still would like to take up the allotted page width but still following that column and cell format I mentioned above.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are you guys go to secret for achieving  perfect  tables in a Quarto Word Report?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ywud9", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11ywud9/how_do_you_get_perfect_tables_for_microsoft_word/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11ywud9/how_do_you_get_perfect_tables_for_microsoft_word/", "subreddit_subscribers": 71012, "created_utc": 1679519525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hello,  \nI am attempting to return specific data from another column if it contains certain matching data from a first column. \n\nThe Top Level List has all permutations of a combination of values. \n\nThe Sub Level List only contains all the possible combinations of only a subset of those values. \n\nThe Returns match is the desired output that populates based on what the Top Level List contains.  \n\n\nThank you in advance for your help!\n\n|Top Level List|Sub Level List|Return Match|\n|:-|:-|:-|\n|A-1-Z-5|1-Z|1-Z|\n|B-1-Z-5|2-Z|1-Z|\n|A-2-Z-5|1-Y|2-Z|\n|B-2-Z-5|2-Y|2-Z|\n|A-1-Y-5||1-Y|\n|B-1-Y-5||1-Y|\n|A-2-Y-5||2-Y|\n|B-2-Y-5||2-Y|\n|A-1-Z-6||1-Z|\n|B-1-Z-6||1-Z|\n|A-2-Z-6||2-Z|\n|B-2-Z-6||2-Z|\n|A-1-Y-6||1-Y|\n|B-1-Y-6||1-Y|\n|A-2-Y-6||2-Y|\n|B-2-Y-6||2-Y|", "author_fullname": "t2_3s1ur6zy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Returning matching subsets of data based on multiple conditions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11z7vo7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679543555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nI am attempting to return specific data from another column if it contains certain matching data from a first column. &lt;/p&gt;\n\n&lt;p&gt;The Top Level List has all permutations of a combination of values. &lt;/p&gt;\n\n&lt;p&gt;The Sub Level List only contains all the possible combinations of only a subset of those values. &lt;/p&gt;\n\n&lt;p&gt;The Returns match is the desired output that populates based on what the Top Level List contains.  &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Top Level List&lt;/th&gt;\n&lt;th align=\"left\"&gt;Sub Level List&lt;/th&gt;\n&lt;th align=\"left\"&gt;Return Match&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-1-Z-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Z&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-1-Z-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Z&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-2-Z-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Y&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-2-Z-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Y&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-1-Y-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-1-Y-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-2-Y-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-2-Y-5&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-1-Z-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-1-Z-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-2-Z-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-2-Z-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Z&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-1-Y-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-1-Y-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;1-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A-2-Y-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B-2-Y-6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2-Y&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11z7vo7", "is_robot_indexable": true, "report_reasons": null, "author": "Sapient333", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11z7vo7/returning_matching_subsets_of_data_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11z7vo7/returning_matching_subsets_of_data_based_on/", "subreddit_subscribers": 71012, "created_utc": 1679543555.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Since we can use Kendal's tau and Spearman's rho to capture the nonlinear dependence between two time series, why do we still need to estimate a copula to do that?", "author_fullname": "t2_23yqc963", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why we need copula?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11z5ccz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679537523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since we can use Kendal&amp;#39;s tau and Spearman&amp;#39;s rho to capture the nonlinear dependence between two time series, why do we still need to estimate a copula to do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11z5ccz", "is_robot_indexable": true, "report_reasons": null, "author": "BOBOLIU", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11z5ccz/why_we_need_copula/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11z5ccz/why_we_need_copula/", "subreddit_subscribers": 71012, "created_utc": 1679537523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding column names of a data frame using $ operator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11z10xf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_3whvqi", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rprogramming", "selftext": "Is there a way to find the column names of a data frame using $ operator? I have written a function to plot x data and variable number of y data using plotly. I am working with a dataset with 20 columns. I need to subset a variable number of columns and plot using plotly. I wrote a function called \"plotly\\_variable\\_y\" that can take arbitrary number of arguments, where the first argument is x.\n\nThe data frame is as follows\n\n`df &lt;- data.frame(x = 1:100, y1 = rnorm(100), y2 = rnorm(100), .... , y20 = rnorm(100))`\n\n`plotly_variable_y(x, y1, y6, y10)` will plot `y1`, `y6` and `y10` in the y axis with common shared `x`\n\n&amp;#x200B;\n\nThe issue is the names of the actual data frame that are quite big with tags, so I would like to keep them as it is.  I was trying to find an easy way to extract the names from df$y1, df$y6, df$y10, etc since the user can call the function easily using Rstudio's ability to autofill the names after typing 'df$'. Any ideas how to go about it?", "author_fullname": "t2_3whvqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding column names of a data frame using $ operator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rprogramming", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11z0dkp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679527928.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679526621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rprogramming", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to find the column names of a data frame using $ operator? I have written a function to plot x data and variable number of y data using plotly. I am working with a dataset with 20 columns. I need to subset a variable number of columns and plot using plotly. I wrote a function called &amp;quot;plotly_variable_y&amp;quot; that can take arbitrary number of arguments, where the first argument is x.&lt;/p&gt;\n\n&lt;p&gt;The data frame is as follows&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;df &amp;lt;- data.frame(x = 1:100, y1 = rnorm(100), y2 = rnorm(100), .... , y20 = rnorm(100))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;plotly_variable_y(x, y1, y6, y10)&lt;/code&gt; will plot &lt;code&gt;y1&lt;/code&gt;, &lt;code&gt;y6&lt;/code&gt; and &lt;code&gt;y10&lt;/code&gt; in the y axis with common shared &lt;code&gt;x&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The issue is the names of the actual data frame that are quite big with tags, so I would like to keep them as it is.  I was trying to find an easy way to extract the names from df$y1, df$y6, df$y10, etc since the user can call the function easily using Rstudio&amp;#39;s ability to autofill the names after typing &amp;#39;df$&amp;#39;. Any ideas how to go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s4vt", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11z0dkp", "is_robot_indexable": true, "report_reasons": null, "author": "acemachine123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rprogramming/comments/11z0dkp/finding_column_names_of_a_data_frame_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rprogramming/comments/11z0dkp/finding_column_names_of_a_data_frame_using/", "subreddit_subscribers": 18466, "created_utc": 1679526621.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679527955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rprogramming", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/rprogramming/comments/11z0dkp/finding_column_names_of_a_data_frame_using/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11z10xf", "is_robot_indexable": true, "report_reasons": null, "author": "acemachine123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11z0dkp", "author_flair_text_color": null, "permalink": "/r/rstats/comments/11z10xf/finding_column_names_of_a_data_frame_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rprogramming/comments/11z0dkp/finding_column_names_of_a_data_frame_using/", "subreddit_subscribers": 71012, "created_utc": 1679527955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hello!\n\nI did the confusion matrix on test data for the xgb model but i need to show performance (accuracy, precision etc) in a table also for training data. Is it possible to do a confusion matrix for training data for xgb model? If yes, how can i do it in Rstudio?", "author_fullname": "t2_86vd985g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confusion Matrix on XGB Gradient Boosting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yybzy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679522485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I did the confusion matrix on test data for the xgb model but i need to show performance (accuracy, precision etc) in a table also for training data. Is it possible to do a confusion matrix for training data for xgb model? If yes, how can i do it in Rstudio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11yybzy", "is_robot_indexable": true, "report_reasons": null, "author": "Mora_2218", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11yybzy/confusion_matrix_on_xgb_gradient_boosting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11yybzy/confusion_matrix_on_xgb_gradient_boosting/", "subreddit_subscribers": 71012, "created_utc": 1679522485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fitted vs residuals looks like crap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_11yv8d6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_84o4kjwv", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pv9LptzHUpVqRNgX_lENnMDl-B9-JB8NPyLTn-Nu7rQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AskStatistics", "selftext": "I am fitting two lmer and checking for heteroskedasticity. Why does it look so crap? Is it ok for me to fit robust mixed models?\n\n&amp;#x200B;\n\na) Minutes\\_Napping\\_SQ2 &lt;- lmer(Minutes\\_Napping \\~ SQ2 + (1|ID), data = dat)\n\nb) Minutes\\_Napping\\_know &lt;- lmer(Minutes\\_Napping \\~ knowledge + (1|ID), data = dat)\n\n&amp;#x200B;\n\nb) dependent variable:\n\nMin. 1st Qu.  Median    Mean 3rd Qu.    Max.\n\n1.0    60.0    90.0   103.2   120.0   750.0\n\npredictor: dichotomous variable - 2 levels\n\nhttps://preview.redd.it/eva8q3uk8cpa1.png?width=700&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=635e0146501eba03a4f8b8879c80d59bd98c7db6\n\nb) dependent variable:\n\nMin. 1st Qu.  Median    Mean 3rd Qu.    Max.\n\n1.0    60.0    90.0   103.2   120.0   750.0\n\npredictor:\n\nMin. 1st Qu.  Median    Mean 3rd Qu.    Max.\n\n1.000   7.000   8.000   7.582   9.000  10.000\n\nhttps://preview.redd.it/tmvm1c759cpa1.png?width=700&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5ed8b0db939962b669c4b65d32eb1c20dbd654ba\n\nHistogram of outcome variable:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/iiuxatsmudpa1.png?width=1536&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7650d579713494b549c790f294dca79c0de81d7f", "author_fullname": "t2_84o4kjwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fitted vs residuals looks like crap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AskStatistics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"iiuxatsmudpa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac4778a7d64e8fa794a96131e29fbfeb189d0e39"}, {"y": 112, "x": 216, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0851d013e2b77bf6aa869f506169df8d1996b6aa"}, {"y": 166, "x": 320, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31580b4b968c53f79a133b2702fff580adaae0f7"}, {"y": 333, "x": 640, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=133ce11c94f98d48aa624e17954c34b6ab1188bf"}, {"y": 500, "x": 960, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10b9842d6d10b4dae89d55895176e205592dc294"}, {"y": 563, "x": 1080, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8e2b8fc01f12e0bc068aa6761413fc2abd7e851"}], "s": {"y": 801, "x": 1536, "u": "https://preview.redd.it/iiuxatsmudpa1.png?width=1536&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7650d579713494b549c790f294dca79c0de81d7f"}, "id": "iiuxatsmudpa1"}, "tmvm1c759cpa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/tmvm1c759cpa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ddb3710adfff6d383bc28a87c767960d772cb0f0"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/tmvm1c759cpa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a78807fbc49cf08e15b470f3a65e502c639ccb4f"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/tmvm1c759cpa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=247cb008b38703bfa66eb1d707f755e4a833afee"}, {"y": 394, "x": 640, "u": "https://preview.redd.it/tmvm1c759cpa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e75fb6179ecb64e18c49e47897ea0f0be8085830"}], "s": {"y": 432, "x": 700, "u": "https://preview.redd.it/tmvm1c759cpa1.png?width=700&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5ed8b0db939962b669c4b65d32eb1c20dbd654ba"}, "id": "tmvm1c759cpa1"}, "eva8q3uk8cpa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/eva8q3uk8cpa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=498a1d609aebf372166ae4188bf8d83319ced0e7"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/eva8q3uk8cpa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f92c206f87859d6c8b1c3e2f37860975a3297f9"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/eva8q3uk8cpa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=926f5bfe171b149d4a60a87af7f72ada06c6cc05"}, {"y": 394, "x": 640, "u": "https://preview.redd.it/eva8q3uk8cpa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c81c46ee4530be51bd06cf9e6aad3e8f1b0fdda"}], "s": {"y": 432, "x": 700, "u": "https://preview.redd.it/eva8q3uk8cpa1.png?width=700&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=635e0146501eba03a4f8b8879c80d59bd98c7db6"}, "id": "eva8q3uk8cpa1"}}, "name": "t3_11yt3bx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679531068.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679511981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskStatistics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am fitting two lmer and checking for heteroskedasticity. Why does it look so crap? Is it ok for me to fit robust mixed models?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;a) Minutes_Napping_SQ2 &amp;lt;- lmer(Minutes_Napping ~ SQ2 + (1|ID), data = dat)&lt;/p&gt;\n\n&lt;p&gt;b) Minutes_Napping_know &amp;lt;- lmer(Minutes_Napping ~ knowledge + (1|ID), data = dat)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;b) dependent variable:&lt;/p&gt;\n\n&lt;p&gt;Min. 1st Qu.  Median    Mean 3rd Qu.    Max.&lt;/p&gt;\n\n&lt;p&gt;1.0    60.0    90.0   103.2   120.0   750.0&lt;/p&gt;\n\n&lt;p&gt;predictor: dichotomous variable - 2 levels&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eva8q3uk8cpa1.png?width=700&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=635e0146501eba03a4f8b8879c80d59bd98c7db6\"&gt;https://preview.redd.it/eva8q3uk8cpa1.png?width=700&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=635e0146501eba03a4f8b8879c80d59bd98c7db6&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;b) dependent variable:&lt;/p&gt;\n\n&lt;p&gt;Min. 1st Qu.  Median    Mean 3rd Qu.    Max.&lt;/p&gt;\n\n&lt;p&gt;1.0    60.0    90.0   103.2   120.0   750.0&lt;/p&gt;\n\n&lt;p&gt;predictor:&lt;/p&gt;\n\n&lt;p&gt;Min. 1st Qu.  Median    Mean 3rd Qu.    Max.&lt;/p&gt;\n\n&lt;p&gt;1.000   7.000   8.000   7.582   9.000  10.000&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tmvm1c759cpa1.png?width=700&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5ed8b0db939962b669c4b65d32eb1c20dbd654ba\"&gt;https://preview.redd.it/tmvm1c759cpa1.png?width=700&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5ed8b0db939962b669c4b65d32eb1c20dbd654ba&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Histogram of outcome variable:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/iiuxatsmudpa1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7650d579713494b549c790f294dca79c0de81d7f\"&gt;https://preview.redd.it/iiuxatsmudpa1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7650d579713494b549c790f294dca79c0de81d7f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sioa", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11yt3bx", "is_robot_indexable": true, "report_reasons": null, "author": "majorcatlover", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AskStatistics/comments/11yt3bx/fitted_vs_residuals_looks_like_crap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/AskStatistics/comments/11yt3bx/fitted_vs_residuals_looks_like_crap/", "subreddit_subscribers": 61781, "created_utc": 1679511981.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1679516269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskStatistics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/AskStatistics/comments/11yt3bx/fitted_vs_residuals_looks_like_crap/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11yv8d6", "is_robot_indexable": true, "report_reasons": null, "author": "majorcatlover", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11yt3bx", "author_flair_text_color": null, "permalink": "/r/rstats/comments/11yv8d6/fitted_vs_residuals_looks_like_crap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/AskStatistics/comments/11yt3bx/fitted_vs_residuals_looks_like_crap/", "subreddit_subscribers": 71012, "created_utc": 1679516269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hello,\n\nI am having issues with the `list.files()`-function. \n\nAssume the following folder structure:\n\nRoot\n-- subfolder1\n-- subfolder1/results.xlsx\n-- subfolder2\n-- subfolder2/results_22.03.2023.xlsx\n-- subfolder3\n-- subfolder3/results.xlsx\n\nI now want to list all xlsx-files within the root-directory, e.g. `root/subfolder1/results.xlsx` and `root/subfolder1/results.xlsx`. The filename is usually `results`, but it may differ, just to mention.\n\nHowever, I don't quite understand how a regex-query interfaces with the `recurse`-argument:\n\n     ## note that this script initially worked on all files being located in the same folder. Now, this has changed.\n    filesuffix = \"xlsx\"\n    pattern &lt;- paste0(\".*\\\\\",filesuffix,\"$\")\n     files &lt;- list.files(\n        path = folder,\n        pattern=pattern,\n        full.names=TRUE,\n        recursive = TRUE)\n\nCan anyone help me with how to set this up? \n\n\nThank you,  \nSincerely,  \n~Gw", "author_fullname": "t2_10mwa9wp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recursive regex-pattern File-selection via list.files() - How to recurse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yf6av", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679482286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am having issues with the &lt;code&gt;list.files()&lt;/code&gt;-function. &lt;/p&gt;\n\n&lt;p&gt;Assume the following folder structure:&lt;/p&gt;\n\n&lt;p&gt;Root\n-- subfolder1\n-- subfolder1/results.xlsx\n-- subfolder2\n-- subfolder2/results_22.03.2023.xlsx\n-- subfolder3\n-- subfolder3/results.xlsx&lt;/p&gt;\n\n&lt;p&gt;I now want to list all xlsx-files within the root-directory, e.g. &lt;code&gt;root/subfolder1/results.xlsx&lt;/code&gt; and &lt;code&gt;root/subfolder1/results.xlsx&lt;/code&gt;. The filename is usually &lt;code&gt;results&lt;/code&gt;, but it may differ, just to mention.&lt;/p&gt;\n\n&lt;p&gt;However, I don&amp;#39;t quite understand how a regex-query interfaces with the &lt;code&gt;recurse&lt;/code&gt;-argument:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; ## note that this script initially worked on all files being located in the same folder. Now, this has changed.\nfilesuffix = &amp;quot;xlsx&amp;quot;\npattern &amp;lt;- paste0(&amp;quot;.*\\\\&amp;quot;,filesuffix,&amp;quot;$&amp;quot;)\n files &amp;lt;- list.files(\n    path = folder,\n    pattern=pattern,\n    full.names=TRUE,\n    recursive = TRUE)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Can anyone help me with how to set this up? &lt;/p&gt;\n\n&lt;p&gt;Thank you,&lt;br/&gt;\nSincerely,&lt;br/&gt;\n~Gw&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11yf6av", "is_robot_indexable": true, "report_reasons": null, "author": "Gewerd_Strauss", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11yf6av/recursive_regexpattern_fileselection_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11yf6av/recursive_regexpattern_fileselection_via/", "subreddit_subscribers": 71012, "created_utc": 1679482286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "", "author_fullname": "t2_vd2d51zd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc49 New Awesome Polars release! \ud83d\ude80 What's new in #Polars? Let's find out!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_11ymfzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/bgwNoMXlddTbQJohaNl81Ygh0xVcjrxUP2CZ6OSUB44.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1679498819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/ddotta/awesome-polars/releases/tag/2023-03-22", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?auto=webp&amp;v=enabled&amp;s=fb571004a9d503f2d33cb43ef81a72f3f93488fb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b761d668a79170a56700c2a485441a76c23f61e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a77ff8884269071e1046c363f5012636074e95c2", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52dad14218527642b101353fedbb9adad5960354", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53954b4736945aff249c1bb2c58a7946c870e935", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=474f211762c0c76a8f67d03893efc84536a83c24", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/f3qU4-RPS_vJLLa55JFeXG16wux98fhnFniCvwRlXU0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2bf283bd4df80e6a7bd641802b9b3fb8eb23ae3", "width": 1080, "height": 540}], "variants": {}, "id": "Bjh07ZHtvcRJZQ1g9WOvxSm3cASjSE0PO0SkdA_kneo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ymfzd", "is_robot_indexable": true, "report_reasons": null, "author": "damiendotta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11ymfzd/new_awesome_polars_release_whats_new_in_polars/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/ddotta/awesome-polars/releases/tag/2023-03-22", "subreddit_subscribers": 71012, "created_utc": 1679498819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hi,\n\nI cannot figure out how to get adjusted R-squared in Lavaan SEM. I just show what I have with a simple X --&gt; Y model below. I can get R-squared with the code under #R square, but I just cannot find the right code to get adjusted R-squared.\n\nHelp is much appreciated. Thank you very much.\n\n&amp;#x200B;\n\nclass(DATA1)  \nlibrary(lavaan)  \nlibrary(haven)  \nlibrary(semPlot)  \nlibrary(semTools)\n\n\\#SEM\n\nSEM&lt;- 'X =\\~ X1+X2+X3  \nY =\\~ Y1 +Y2 + Y3  \nY \\~ X\n\n'\n\n\\#variances\n\n\\#fitting SEM model\n\nfit1&lt;-sem(SEM,data=DATA1)  \nfit1  \nsummary(fit1, standardized=TRUE)  \nmodindices(fit1, sort. = TRUE)  \ninspect(fit1, what = \"std\")\n\n\\#R Square\n\ninspect(fit1, 'r2')  \nfitmeasures(fit1)  \nfitmeasures(fit1,c(\"gfi\",\"agfi\",\"nfi\",\"cfi\",\"srmr\",\"rmsea\",\"tli\"))\n\n\\#Reliability\n\nreliability(fit1)\n\n\\#visual representation\n\nsemPaths(fit1,\"std\")", "author_fullname": "t2_aq3e3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get adjusted R-squared in Lavaan SEM?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xsxrg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679429699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I cannot figure out how to get adjusted R-squared in Lavaan SEM. I just show what I have with a simple X --&amp;gt; Y model below. I can get R-squared with the code under #R square, but I just cannot find the right code to get adjusted R-squared.&lt;/p&gt;\n\n&lt;p&gt;Help is much appreciated. Thank you very much.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;class(DATA1)&lt;br/&gt;\nlibrary(lavaan)&lt;br/&gt;\nlibrary(haven)&lt;br/&gt;\nlibrary(semPlot)&lt;br/&gt;\nlibrary(semTools)&lt;/p&gt;\n\n&lt;p&gt;#SEM&lt;/p&gt;\n\n&lt;p&gt;SEM&amp;lt;- &amp;#39;X =~ X1+X2+X3&lt;br/&gt;\nY =~ Y1 +Y2 + Y3&lt;br/&gt;\nY ~ X&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;#variances&lt;/p&gt;\n\n&lt;p&gt;#fitting SEM model&lt;/p&gt;\n\n&lt;p&gt;fit1&amp;lt;-sem(SEM,data=DATA1)&lt;br/&gt;\nfit1&lt;br/&gt;\nsummary(fit1, standardized=TRUE)&lt;br/&gt;\nmodindices(fit1, sort. = TRUE)&lt;br/&gt;\ninspect(fit1, what = &amp;quot;std&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;#R Square&lt;/p&gt;\n\n&lt;p&gt;inspect(fit1, &amp;#39;r2&amp;#39;)&lt;br/&gt;\nfitmeasures(fit1)&lt;br/&gt;\nfitmeasures(fit1,c(&amp;quot;gfi&amp;quot;,&amp;quot;agfi&amp;quot;,&amp;quot;nfi&amp;quot;,&amp;quot;cfi&amp;quot;,&amp;quot;srmr&amp;quot;,&amp;quot;rmsea&amp;quot;,&amp;quot;tli&amp;quot;))&lt;/p&gt;\n\n&lt;p&gt;#Reliability&lt;/p&gt;\n\n&lt;p&gt;reliability(fit1)&lt;/p&gt;\n\n&lt;p&gt;#visual representation&lt;/p&gt;\n\n&lt;p&gt;semPaths(fit1,&amp;quot;std&amp;quot;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11xsxrg", "is_robot_indexable": true, "report_reasons": null, "author": "mrmaxilicious", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11xsxrg/how_do_i_get_adjusted_rsquared_in_lavaan_sem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11xsxrg/how_do_i_get_adjusted_rsquared_in_lavaan_sem/", "subreddit_subscribers": 71012, "created_utc": 1679429699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Is there any package or guide about working with sockets on R? I've found very little material.   \nI am trying to replicate an implementation with have on python based on [python sockets](https://docs.python.org/3/library/socket.html) but I can't find something as extensive.  \n\n\nI see is some really lacking R features on sockets, even reading binaries of unknown length seems difficult using sockets, I've tried doing it transforming this from [Char to Raw](http://blog.corynissen.com/2013/05/using-r-to-communicate-via-socket.html) but with very little success.  \nOr the recommended way is going through c++ and Rcpp?  \n\n\nThanks :)", "author_fullname": "t2_171kvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "R socket programming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xmnfk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679417300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any package or guide about working with sockets on R? I&amp;#39;ve found very little material.&lt;br/&gt;\nI am trying to replicate an implementation with have on python based on &lt;a href=\"https://docs.python.org/3/library/socket.html\"&gt;python sockets&lt;/a&gt; but I can&amp;#39;t find something as extensive.  &lt;/p&gt;\n\n&lt;p&gt;I see is some really lacking R features on sockets, even reading binaries of unknown length seems difficult using sockets, I&amp;#39;ve tried doing it transforming this from &lt;a href=\"http://blog.corynissen.com/2013/05/using-r-to-communicate-via-socket.html\"&gt;Char to Raw&lt;/a&gt; but with very little success.&lt;br/&gt;\nOr the recommended way is going through c++ and Rcpp?  &lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uQnwG5vj0W2B8UmXvnpbBF8bitWWN9ApOpjGDNFekLw.jpg?auto=webp&amp;v=enabled&amp;s=8cffb70177a255a5d273f49b07a192aae79dd5d1", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/uQnwG5vj0W2B8UmXvnpbBF8bitWWN9ApOpjGDNFekLw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00b81de315991e3643052ea46585a6ef9bd8c2d5", "width": 108, "height": 108}], "variants": {}, "id": "qsyApzksUdlxqY7z2ubJCNmhQilhXIOl25dSHcQQLB4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11xmnfk", "is_robot_indexable": true, "report_reasons": null, "author": "ehellas", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11xmnfk/r_socket_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11xmnfk/r_socket_programming/", "subreddit_subscribers": 71012, "created_utc": 1679417300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hello,\n\n&amp;#x200B;\n\nI'm new to R and getting a bit cofused.  I'm trying to make a decomposition chart using quarterly data using the following code:  \n\n\n bovine &lt;- ts(March\\_15\\_Charts\\_for\\_R\\_, frequency = 4, start = c(2016,1,1)) \n\nplot.ts(bovine)\n\ndec &lt;- decompose(bovine, type = (\"additive\"))\n\ndec\n\nplot(dec)\n\nMy output looks like this:\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/o61yjtroo4pa1.png?width=840&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=15ff283dd98933945469019ae47a1c2c893954bd\n\nThere are two main problems.  The axis are unreadable, and the time (x axis) goes to 2030, even though my data only goes to 2022.  Any help would be appreciated!", "author_fullname": "t2_sagm79xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Making a decomposition chart in R", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "media_metadata": {"o61yjtroo4pa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/o61yjtroo4pa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a19df20555e5aff28d88ce72ed8f73bb3dd0c2a7"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/o61yjtroo4pa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7188425a9b6846868cbb864cbda45497a173d6b"}, {"y": 204, "x": 320, "u": "https://preview.redd.it/o61yjtroo4pa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e28fff76211aef4f89894eccfd62aa86cfce1b9"}, {"y": 409, "x": 640, "u": "https://preview.redd.it/o61yjtroo4pa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88a96f4e5c3174eb21f2737266fee1eac65bf69f"}], "s": {"y": 537, "x": 840, "u": "https://preview.redd.it/o61yjtroo4pa1.png?width=840&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=15ff283dd98933945469019ae47a1c2c893954bd"}, "id": "o61yjtroo4pa1"}}, "name": "t3_11xo3m4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/7xbEYfJ57okPItypOfiRJSoYyGBp7jK8mg1ebZSZ3g8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679420153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to R and getting a bit cofused.  I&amp;#39;m trying to make a decomposition chart using quarterly data using the following code:  &lt;/p&gt;\n\n&lt;p&gt;bovine &amp;lt;- ts(March_15_Charts_for_R_, frequency = 4, start = c(2016,1,1)) &lt;/p&gt;\n\n&lt;p&gt;plot.ts(bovine)&lt;/p&gt;\n\n&lt;p&gt;dec &amp;lt;- decompose(bovine, type = (&amp;quot;additive&amp;quot;))&lt;/p&gt;\n\n&lt;p&gt;dec&lt;/p&gt;\n\n&lt;p&gt;plot(dec)&lt;/p&gt;\n\n&lt;p&gt;My output looks like this:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/o61yjtroo4pa1.png?width=840&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=15ff283dd98933945469019ae47a1c2c893954bd\"&gt;https://preview.redd.it/o61yjtroo4pa1.png?width=840&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=15ff283dd98933945469019ae47a1c2c893954bd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There are two main problems.  The axis are unreadable, and the time (x axis) goes to 2030, even though my data only goes to 2022.  Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11xo3m4", "is_robot_indexable": true, "report_reasons": null, "author": "HeadZookeepergame634", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11xo3m4/making_a_decomposition_chart_in_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11xo3m4/making_a_decomposition_chart_in_r/", "subreddit_subscribers": 71012, "created_utc": 1679420153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "This is my first time using LDA, and I wrote some code that gives the LDA. However, I am unsure of how to find the test sensitivity and test accuracy for the Bayes classifier from the output I was giving. I was hoping someone could just lead me in the right direction.", "author_fullname": "t2_e7ttto8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find Bayes Classifiers from LDA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xok4m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679421094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first time using LDA, and I wrote some code that gives the LDA. However, I am unsure of how to find the test sensitivity and test accuracy for the Bayes classifier from the output I was giving. I was hoping someone could just lead me in the right direction.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11xok4m", "is_robot_indexable": true, "report_reasons": null, "author": "JoeMamaBiden2020", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11xok4m/how_to_find_bayes_classifiers_from_lda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11xok4m/how_to_find_bayes_classifiers_from_lda/", "subreddit_subscribers": 71012, "created_utc": 1679421094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hello, if you have a minute to spare, it would be great if you could fill out this form for my stats project!\n\nThe form is completely anonymous. It just asks you to rate someone's intelligence 1-10 based on a picture of them.\n\nHere is the form: [https://allocate.monster/EJUYAKUC](https://allocate.monster/EJUYAKUC)\n\nThank you", "author_fullname": "t2_sep3ysij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collecting data for stats survey: rate intelligence 1-10", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xl36i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679414267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, if you have a minute to spare, it would be great if you could fill out this form for my stats project!&lt;/p&gt;\n\n&lt;p&gt;The form is completely anonymous. It just asks you to rate someone&amp;#39;s intelligence 1-10 based on a picture of them.&lt;/p&gt;\n\n&lt;p&gt;Here is the form: &lt;a href=\"https://allocate.monster/EJUYAKUC\"&gt;https://allocate.monster/EJUYAKUC&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?auto=webp&amp;v=enabled&amp;s=e11b9036282001069ac29322d15043e0f91df831", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3c20db583f75db0c9701bc026b02484dd1e59d1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e7c4e0b37d6739ee71c5646505637060e5dcf7c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69b0c2acfb92d4a0e7b01a6f4db0e56d02b5cbf2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10bf012dd65e6d6bc88074e27ade21a8866e847d", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55fc209253279a2e6091862a5424dc731543d439", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZasYOSs1_JCZ5tTtiryAQ2Z3WbKbBkZdj40_prCCi8Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2231ae46054a762cd93e2adbdaf394cc31bd3792", "width": 1080, "height": 567}], "variants": {}, "id": "jWLel8LjwCR0JpQtoRbys7Wj7KXVkdAPGqG-8y6OMg0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11xl36i", "is_robot_indexable": true, "report_reasons": null, "author": "1-Emil", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11xl36i/collecting_data_for_stats_survey_rate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11xl36i/collecting_data_for_stats_survey_rate/", "subreddit_subscribers": 71012, "created_utc": 1679414267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "", "author_fullname": "t2_4d8l6u4ia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with my ggplot area graph, it's supposedly a one-variable graph, but asks for y", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_11wmwwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/FJErsBYXUgrc7WdqKZTDLGLE-gvzl4MJDVefbMpPTf4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1679328452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lcrzxra14xoa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lcrzxra14xoa1.png?auto=webp&amp;v=enabled&amp;s=493d03c919096160f199108b5ca3dd15d6d2c5e9", "width": 1086, "height": 728}, "resolutions": [{"url": "https://preview.redd.it/lcrzxra14xoa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a74a75e1f94a723b4a32941bdf0e54c80900730", "width": 108, "height": 72}, {"url": "https://preview.redd.it/lcrzxra14xoa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c99254f6f851ffb07bfac97d14d5a5ff8179c7db", "width": 216, "height": 144}, {"url": "https://preview.redd.it/lcrzxra14xoa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f548f05c00071333be8098b9eb0e258cf604cfd9", "width": 320, "height": 214}, {"url": "https://preview.redd.it/lcrzxra14xoa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77ffe38eeb55013234dfd002b4d85885a2cd4bf8", "width": 640, "height": 429}, {"url": "https://preview.redd.it/lcrzxra14xoa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce4b6d2ce7f1872ff8af2ac9aa7e49792b1349f7", "width": 960, "height": 643}, {"url": "https://preview.redd.it/lcrzxra14xoa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e0584df424cec2e6cb94e5b3140042aa31f735f", "width": 1080, "height": 723}], "variants": {}, "id": "6csFR4GlddWU4MX0d_9Bn9leRNBvcT1r5cceioOQWak"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wmwwf", "is_robot_indexable": true, "report_reasons": null, "author": "Fan_of_tasy", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wmwwf/i_need_help_with_my_ggplot_area_graph_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lcrzxra14xoa1.png", "subreddit_subscribers": 71012, "created_utc": 1679328452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hi all,\n\nRight off the bat - I don't have the code to show you, it's at work.\n\nI'm updating a script to a simpler reporting process.\n\nThe inputs to my code are identical in every way except size - we were able to make some changes earlier in the process while maintaining the format of the data inputs to this script in question.\n\nSo I'm trying to merge two data tables on multiple ID variables like this:\n\n    df_new &lt;- merge(df_A, df_B,\n        by.x = (col1, col2, col3),\n        by.y = (col1, col2, col3)\n        all.y = TRUE)\n\ndf\\_A has a column called Counts (integers) and it is filled with some 0s and a bunch of numbers (there are counts in some date ranges and not in others). df\\_b does not have this column.\n\nMy *production* version of this code segment is *identical*. I've compared the two scripts (there are some changes believe me!) and the production version outputs what we expect: some values are the numbers as they were in df\\_A, and NAs otherwise because they do not exist in df\\_B.\n\nHowever, when I execute the merge, df\\_new has the proper columns, however, the values in the Counts column are ***all NA*****s.** This has impact down the line in an Excel pivot table which needs these values.\n\nTo be clear: The production code and new code segments are the same...I'm pretty confused lol.\n\nI've read the data.table docs and read the merge function's docs and I couldn't really figure out what the problem is. I googled around a bit too, and most of the similar issues come back to original askers not understanding the docs. (Maybe I'm in that boat too)\n\nSome things I have done: compared data types in df\\_A, df\\_B, df\\_new between the production code's data tables against the new code. There were some differences. Some places had char data types when they should have been factors. I didn't think this would be issue, but I set chars to factors to no avail (cause why not?), I also set some nums to ints. I've also done some !anyNA()s, unique(df\\_new$Counts), etc. There should be a million or so non-NA values, and there are none - quite strange. I have also checked step-by-step with intermediate datatables and dataframes to see where things go awry, and it is exactly at this step.\n\nI would greatly appreciate any help in terms of a straight comment, articles, explanation of the docs, or something of that nature.\n\nThanks everyone =)", "author_fullname": "t2_73ph2yes", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data.table merge Creating Unexpected NAs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wyyn7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679352825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Right off the bat - I don&amp;#39;t have the code to show you, it&amp;#39;s at work.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m updating a script to a simpler reporting process.&lt;/p&gt;\n\n&lt;p&gt;The inputs to my code are identical in every way except size - we were able to make some changes earlier in the process while maintaining the format of the data inputs to this script in question.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m trying to merge two data tables on multiple ID variables like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df_new &amp;lt;- merge(df_A, df_B,\n    by.x = (col1, col2, col3),\n    by.y = (col1, col2, col3)\n    all.y = TRUE)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;df_A has a column called Counts (integers) and it is filled with some 0s and a bunch of numbers (there are counts in some date ranges and not in others). df_b does not have this column.&lt;/p&gt;\n\n&lt;p&gt;My &lt;em&gt;production&lt;/em&gt; version of this code segment is &lt;em&gt;identical&lt;/em&gt;. I&amp;#39;ve compared the two scripts (there are some changes believe me!) and the production version outputs what we expect: some values are the numbers as they were in df_A, and NAs otherwise because they do not exist in df_B.&lt;/p&gt;\n\n&lt;p&gt;However, when I execute the merge, df_new has the proper columns, however, the values in the Counts column are &lt;strong&gt;&lt;em&gt;all NA&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;s.&lt;/strong&gt; This has impact down the line in an Excel pivot table which needs these values.&lt;/p&gt;\n\n&lt;p&gt;To be clear: The production code and new code segments are the same...I&amp;#39;m pretty confused lol.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read the data.table docs and read the merge function&amp;#39;s docs and I couldn&amp;#39;t really figure out what the problem is. I googled around a bit too, and most of the similar issues come back to original askers not understanding the docs. (Maybe I&amp;#39;m in that boat too)&lt;/p&gt;\n\n&lt;p&gt;Some things I have done: compared data types in df_A, df_B, df_new between the production code&amp;#39;s data tables against the new code. There were some differences. Some places had char data types when they should have been factors. I didn&amp;#39;t think this would be issue, but I set chars to factors to no avail (cause why not?), I also set some nums to ints. I&amp;#39;ve also done some !anyNA()s, unique(df_new$Counts), etc. There should be a million or so non-NA values, and there are none - quite strange. I have also checked step-by-step with intermediate datatables and dataframes to see where things go awry, and it is exactly at this step.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate any help in terms of a straight comment, articles, explanation of the docs, or something of that nature.&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone =)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wyyn7", "is_robot_indexable": true, "report_reasons": null, "author": "The_Mootz_Pallucci", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wyyn7/datatable_merge_creating_unexpected_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wyyn7/datatable_merge_creating_unexpected_nas/", "subreddit_subscribers": 71012, "created_utc": 1679352825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hi!  I'm struggling with figuring out how to use ggplot2 to get a bar graph that I can very easily make in excel.\n\nMy dataset looks like this:\n\n|ID|time\\_1|time\\_2|time\\_3|char|\n|:-|:-|:-|:-|:-|\n|1|TRUE|TRUE|FALSE|TRUE|\n|2|TRUE|TRUE|TRUE|TRUE|\n|3|FALSE|FALSE|FALSE|FALSE|\n|4|TRUE|TRUE|FALSE|FALSE|\n|5|FALSE|FALSE|TRUE|FALSE|\n\nI would like to have a bar graph of TRUE percentages at each time point and then compare those with the char variable.  I can use tbl\\_summary to get the numbers and I have been able to make line graphs with individual datapoints by pivoting the data longer.  However, I can't figure out how to make  these more summary type bar graphs.  The following can get me 1 timepoint by count instead of percentage:\n\n    ggplot(df, aes(x = time_1, fill = char)) + geom_bar(position = 'dodge2')\n\nI feel like I'm missing something basic here!   Thank you!", "author_fullname": "t2_f6i7n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ggplot2 assistance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wlns1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679325815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!  I&amp;#39;m struggling with figuring out how to use ggplot2 to get a bar graph that I can very easily make in excel.&lt;/p&gt;\n\n&lt;p&gt;My dataset looks like this:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID&lt;/th&gt;\n&lt;th align=\"left\"&gt;time_1&lt;/th&gt;\n&lt;th align=\"left\"&gt;time_2&lt;/th&gt;\n&lt;th align=\"left\"&gt;time_3&lt;/th&gt;\n&lt;th align=\"left\"&gt;char&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;td align=\"left\"&gt;TRUE&lt;/td&gt;\n&lt;td align=\"left\"&gt;FALSE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I would like to have a bar graph of TRUE percentages at each time point and then compare those with the char variable.  I can use tbl_summary to get the numbers and I have been able to make line graphs with individual datapoints by pivoting the data longer.  However, I can&amp;#39;t figure out how to make  these more summary type bar graphs.  The following can get me 1 timepoint by count instead of percentage:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ggplot(df, aes(x = time_1, fill = char)) + geom_bar(position = &amp;#39;dodge2&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I feel like I&amp;#39;m missing something basic here!   Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wlns1", "is_robot_indexable": true, "report_reasons": null, "author": "11incrocs", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wlns1/ggplot2_assistance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wlns1/ggplot2_assistance/", "subreddit_subscribers": 71012, "created_utc": 1679325815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hi everyone,\n\nLooking for a comprehensive guide to running a moderated mediation analysis using lavaan when the moderator variable is categorical. \n\nI\u2019m a PhD student and I\u2019m using SEM to test a model. I understand the lavaan syntax but can\u2019t find a guide anywhere for running moderated mediation analysis. I would use the centred variable method, like the below resource does, but I have a categorical variable. \n\nhttps://ademos.people.uic.edu/Chapter15.html#5_moderated_mediation_analyses_using_%E2%80%9Clavaan%E2%80%9D_package\n\nI\u2019m a bit stuck, and I\u2019ve had to teach myself the majority of the SEM stuff so far so not even sure if I\u2019m confusing myself. \n\nThank you in advance for any help!", "author_fullname": "t2_hhugmykw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lavaan SEM moderated mediation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wds4b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679303872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Looking for a comprehensive guide to running a moderated mediation analysis using lavaan when the moderator variable is categorical. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m a PhD student and I\u2019m using SEM to test a model. I understand the lavaan syntax but can\u2019t find a guide anywhere for running moderated mediation analysis. I would use the centred variable method, like the below resource does, but I have a categorical variable. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ademos.people.uic.edu/Chapter15.html#5_moderated_mediation_analyses_using_%E2%80%9Clavaan%E2%80%9D_package\"&gt;https://ademos.people.uic.edu/Chapter15.html#5_moderated_mediation_analyses_using_%E2%80%9Clavaan%E2%80%9D_package&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a bit stuck, and I\u2019ve had to teach myself the majority of the SEM stuff so far so not even sure if I\u2019m confusing myself. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wds4b", "is_robot_indexable": true, "report_reasons": null, "author": "Double-Character74", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wds4b/lavaan_sem_moderated_mediation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wds4b/lavaan_sem_moderated_mediation/", "subreddit_subscribers": 71012, "created_utc": 1679303872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "I have the following data in R:\n\n    my_data &lt;- data.frame(date_var = c(\"2015-01\", \"2016-43\"), rain_fall = c(34, 23)) \n\nThe date is currently in \"chr\" format and contains the year followed by the week number.\n\n**I am trying to convert this date using the \"**[**as.Date**](https://as.Date)**()** **\" function.**\n\nHowever, when I do this, I get the following error:\n\n    &gt; as.Date(my_data$date_var) Error in charToDate(x) :    character string is not in a standard unambiguous format \n\nI tried  this as well:\n\n    as.Date(as.character(my_data$date_var),\"%Y%w\")\n     [1] NA NA \n\nBut it did not work.\n\nCan someone please show me how to fix this?\n\nThanks!\n\n**Note:** Eventually, I would like to apply the following code on the resulting data frame for time series analysis:\n\n    ts_data &lt;- ts(my_data$rain_fall frequency = 52, start = c(year(min(my_data$date_var))", "author_fullname": "t2_3tosvccj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble With Date Conversion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wo6o9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679331175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the following data in R:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;my_data &amp;lt;- data.frame(date_var = c(&amp;quot;2015-01&amp;quot;, &amp;quot;2016-43&amp;quot;), rain_fall = c(34, 23)) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The date is currently in &amp;quot;chr&amp;quot; format and contains the year followed by the week number.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I am trying to convert this date using the &amp;quot;&lt;/strong&gt;&lt;a href=\"https://as.Date\"&gt;&lt;strong&gt;as.Date&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;()&lt;/strong&gt; &lt;strong&gt;&amp;quot; function.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;However, when I do this, I get the following error:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;gt; as.Date(my_data$date_var) Error in charToDate(x) :    character string is not in a standard unambiguous format \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I tried  this as well:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;as.Date(as.character(my_data$date_var),&amp;quot;%Y%w&amp;quot;)\n [1] NA NA \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But it did not work.&lt;/p&gt;\n\n&lt;p&gt;Can someone please show me how to fix this?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Eventually, I would like to apply the following code on the resulting data frame for time series analysis:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ts_data &amp;lt;- ts(my_data$rain_fall frequency = 52, start = c(year(min(my_data$date_var))\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wo6o9", "is_robot_indexable": true, "report_reasons": null, "author": "jj4646", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wo6o9/trouble_with_date_conversion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wo6o9/trouble_with_date_conversion/", "subreddit_subscribers": 71012, "created_utc": 1679331175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "I am thinking what to do when I don\u2019t have existing functions, but I can do the algebra to get the inverse CDF in closed-form.  Can I just round or take the floor of the result?", "author_fullname": "t2_y7l57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] Can you use inverse CDF as a way to simulate draws from an integer distribution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wmmhn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679327855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking what to do when I don\u2019t have existing functions, but I can do the algebra to get the inverse CDF in closed-form.  Can I just round or take the floor of the result?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wmmhn", "is_robot_indexable": true, "report_reasons": null, "author": "sonicking12", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wmmhn/q_can_you_use_inverse_cdf_as_a_way_to_simulate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wmmhn/q_can_you_use_inverse_cdf_as_a_way_to_simulate/", "subreddit_subscribers": 71012, "created_utc": 1679327855.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hi all,\n\nI want to create a new data frame and need some help.\n\n&amp;#x200B;\n\ndf &lt;- data\\_flow %&gt;%\n\n  data.frame(\n\nvalue1 = ifelse(Pointer == 138, Flow, NA),\n\nvalue2 = ifelse(Pointer == 150, PIT\\_mean, NA),\n\nvalue3 = ifelse(Pointer == 148, PIT\\_max, NA),\n\n  )\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nPointer, Flow, PIT\\_mean, PIT\\_max are columns in data\\_flow\n\nwhy it's not working, and how do I make it without using $ all the time?", "author_fullname": "t2_f4mmz568", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating data frame", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wdo6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679303469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I want to create a new data frame and need some help.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;df &amp;lt;- data_flow %&amp;gt;%&lt;/p&gt;\n\n&lt;p&gt;data.frame(&lt;/p&gt;\n\n&lt;p&gt;value1 = ifelse(Pointer == 138, Flow, NA),&lt;/p&gt;\n\n&lt;p&gt;value2 = ifelse(Pointer == 150, PIT_mean, NA),&lt;/p&gt;\n\n&lt;p&gt;value3 = ifelse(Pointer == 148, PIT_max, NA),&lt;/p&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Pointer, Flow, PIT_mean, PIT_max are columns in data_flow&lt;/p&gt;\n\n&lt;p&gt;why it&amp;#39;s not working, and how do I make it without using $ all the time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wdo6t", "is_robot_indexable": true, "report_reasons": null, "author": "Goomal", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wdo6t/creating_data_frame/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wdo6t/creating_data_frame/", "subreddit_subscribers": 71012, "created_utc": 1679303469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "So I have an excel with the murder rates of every state divided by year and state, the excel file has three columns: murder\\_rate, state\\_id and year. I want to add them as another variable in the df I'm working with that already has an id variable for every state and year (I made sure the names were the same in the excel file columns and in the data frame I was already working with). \n\nTo do that, I loaded the murder rates excel file in my environment and then used df2 &lt;- merge(df, murder\\_rates, by = c(\"state\\_id\", \"year\")). \n\nBut the output of table(df$murder\\_rates, df$state\\_id) shows me something like this: \n\n||New York|Boston|Chicago|\n|:-|:-|:-|:-|\n|2.49|0|20980|0|\n| 2.98|40032|0|30456|\n|2.99|0|0|0|\n\nI made up the numbers, but it's basically the number of observations for every murder rate. But I need it to be something like this:\n\n|New York|Boston|Chicago|\n|:-|:-|:-|\n|2.49|2.98|2.99|\n\nHow can I do that?\n\nAnother problem is that if I try to table the murder rates by year and state it just shows 0s. Ultimately I need the variable data to be organized like this: \n\n&amp;#x200B;\n\n||New York|Boston|\n|:-|:-|:-|\n|*2016*|2.49|2.98|\n|*2017*|2.54|2.87|\n|*2018*|2.67|2.76|\n\nor: \n\n|*2016*|||\n|:-|:-|:-|\n|2.49|New York ||\n|2.98|Boston||\n|*2017*|||\n|2.54|New York ||\n|2.87|Boston||\n|*2018*|||\n|2.67|New York ||\n|2.76|Boston||\n\nWhat should I do?", "author_fullname": "t2_5lka8l94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to add a new variable to my database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wgmqx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679312878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an excel with the murder rates of every state divided by year and state, the excel file has three columns: murder_rate, state_id and year. I want to add them as another variable in the df I&amp;#39;m working with that already has an id variable for every state and year (I made sure the names were the same in the excel file columns and in the data frame I was already working with). &lt;/p&gt;\n\n&lt;p&gt;To do that, I loaded the murder rates excel file in my environment and then used df2 &amp;lt;- merge(df, murder_rates, by = c(&amp;quot;state_id&amp;quot;, &amp;quot;year&amp;quot;)). &lt;/p&gt;\n\n&lt;p&gt;But the output of table(df$murder_rates, df$state_id) shows me something like this: &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;New York&lt;/th&gt;\n&lt;th align=\"left\"&gt;Boston&lt;/th&gt;\n&lt;th align=\"left\"&gt;Chicago&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.49&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;20980&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.98&lt;/td&gt;\n&lt;td align=\"left\"&gt;40032&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;30456&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.99&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I made up the numbers, but it&amp;#39;s basically the number of observations for every murder rate. But I need it to be something like this:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;New York&lt;/th&gt;\n&lt;th align=\"left\"&gt;Boston&lt;/th&gt;\n&lt;th align=\"left\"&gt;Chicago&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.49&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.98&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.99&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;How can I do that?&lt;/p&gt;\n\n&lt;p&gt;Another problem is that if I try to table the murder rates by year and state it just shows 0s. Ultimately I need the variable data to be organized like this: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;New York&lt;/th&gt;\n&lt;th align=\"left\"&gt;Boston&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;2016&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.49&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.98&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;2017&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.54&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.87&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;2018&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.67&lt;/td&gt;\n&lt;td align=\"left\"&gt;2.76&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;or: &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;&lt;em&gt;2016&lt;/em&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;th align=\"left\"&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.49&lt;/td&gt;\n&lt;td align=\"left\"&gt;New York&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.98&lt;/td&gt;\n&lt;td align=\"left\"&gt;Boston&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;2017&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.54&lt;/td&gt;\n&lt;td align=\"left\"&gt;New York&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.87&lt;/td&gt;\n&lt;td align=\"left\"&gt;Boston&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;2018&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.67&lt;/td&gt;\n&lt;td align=\"left\"&gt;New York&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2.76&lt;/td&gt;\n&lt;td align=\"left\"&gt;Boston&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;What should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11wgmqx", "is_robot_indexable": true, "report_reasons": null, "author": "Johnmayer000", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11wgmqx/how_to_add_a_new_variable_to_my_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11wgmqx/how_to_add_a_new_variable_to_my_database/", "subreddit_subscribers": 71012, "created_utc": 1679312878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Hello everyone, first of all, sorry if this is a duplicate query.\n\nI am having trouble refining a data frame. In my data frame, I have a large number of missing values, and it is a time series data, so values are related to the month and year. I am trying to replace the missing values (NA) with the average. For that, I am using the `na.aggregate` function from the `zoo` package in R, But if I decide to replace the missing values by month, it takes the average of all similar months irrespective of the different years. \n\n&amp;#x200B;\n\nAny idea how I can replace NA with the monthly average separated by the year or if there is a better algorithm?", "author_fullname": "t2_55ip6b36", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing missing values with the monthly average", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vszqb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679249876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, first of all, sorry if this is a duplicate query.&lt;/p&gt;\n\n&lt;p&gt;I am having trouble refining a data frame. In my data frame, I have a large number of missing values, and it is a time series data, so values are related to the month and year. I am trying to replace the missing values (NA) with the average. For that, I am using the &lt;code&gt;na.aggregate&lt;/code&gt; function from the &lt;code&gt;zoo&lt;/code&gt; package in R, But if I decide to replace the missing values by month, it takes the average of all similar months irrespective of the different years. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any idea how I can replace NA with the monthly average separated by the year or if there is a better algorithm?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11vszqb", "is_robot_indexable": true, "report_reasons": null, "author": "stats4every1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11vszqb/replacing_missing_values_with_the_monthly_average/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11vszqb/replacing_missing_values_with_the_monthly_average/", "subreddit_subscribers": 71012, "created_utc": 1679249876.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using second dataframe as lookup to fill NA rows - unsure how to proceed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vz0ao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "3de1f7ee-0bca-11e6-a19f-0efeacb460d9", "is_original_content": false, "author_fullname": "t2_s1qhx", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "github", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rprogramming", "selftext": "Hi!\nI have ran into a problem with merging two dataframe.\n\nI have two dataframes. df1 looks like this:\n\n\n\nSubject | Gender | Task1 | Drug | Chol | Task2\n-------|------|-----|----|----|-----\n1 | Male | Yes | 1 | 366 | NA\n1 | Male | Yes | 2 | 377 | NA\n1 | Male | Yes | 3 | 123 | NA\n1 | Male | NA | 1 | NA | Yes\u00a0\n1 | Male | NA | 2 | NA | Yes\n1 | Male | NA | 8 | NA | Yes\n\n\nAnd  I have a second \"lookup\" dataframe (df2):\n\n\n\nDrug | Gender | Chol\n----|------|----\n1 | Male | 366\n1 | Female | 477\n8 | Male | 17\n8 | Female | 33\n3 | Male | 77\n3 | Female | 11\n\nEssentially, I want to use data from df2 to fill the rows in df1$chol, which (all conditions have to be met): \n\n1) Have \"yes\" in df1$Task 2\n2) Have NA in df1$chol\n\nbasing on df2$Gender and df2$drug. So, for example, the resulting dataframe should be something like that (highlighted replaced NAs in bold):\n\nSubject | Gender | Task1 | Drug | Chol | Task2\n-------|------|-----|----|----|-----\n1 | Male | Yes | 1 | 366 | NA\n1 | Male | Yes | 2 | 377 | NA\n1 | Male | Yes | 3 | 123 | NA\n1 | Male | NA | 1 | **366** | Yes\u00a0\n1 | Male | NA | 2 | **377** | Yes\n1 | Male | NA | 8 | **17** | Yes\n\nAny help will be greatly appreciated.", "author_fullname": "t2_s1qhx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using second dataframe as lookup to fill NA rows - unsure how to proceed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rprogramming", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vyzjk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679262727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rprogramming", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!\nI have ran into a problem with merging two dataframe.&lt;/p&gt;\n\n&lt;p&gt;I have two dataframes. df1 looks like this:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Subject&lt;/th&gt;\n&lt;th&gt;Gender&lt;/th&gt;\n&lt;th&gt;Task1&lt;/th&gt;\n&lt;th&gt;Drug&lt;/th&gt;\n&lt;th&gt;Chol&lt;/th&gt;\n&lt;th&gt;Task2&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;366&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;377&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;123&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;Yes\u00a0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;And  I have a second &amp;quot;lookup&amp;quot; dataframe (df2):&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Drug&lt;/th&gt;\n&lt;th&gt;Gender&lt;/th&gt;\n&lt;th&gt;Chol&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;366&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Female&lt;/td&gt;\n&lt;td&gt;477&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;17&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;Female&lt;/td&gt;\n&lt;td&gt;33&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;77&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;Female&lt;/td&gt;\n&lt;td&gt;11&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Essentially, I want to use data from df2 to fill the rows in df1$chol, which (all conditions have to be met): &lt;/p&gt;\n\n&lt;p&gt;1) Have &amp;quot;yes&amp;quot; in df1$Task 2\n2) Have NA in df1$chol&lt;/p&gt;\n\n&lt;p&gt;basing on df2$Gender and df2$drug. So, for example, the resulting dataframe should be something like that (highlighted replaced NAs in bold):&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Subject&lt;/th&gt;\n&lt;th&gt;Gender&lt;/th&gt;\n&lt;th&gt;Task1&lt;/th&gt;\n&lt;th&gt;Drug&lt;/th&gt;\n&lt;th&gt;Chol&lt;/th&gt;\n&lt;th&gt;Task2&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;366&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;377&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;123&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;366&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;Yes\u00a0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;377&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;Male&lt;/td&gt;\n&lt;td&gt;NA&lt;/td&gt;\n&lt;td&gt;8&lt;/td&gt;\n&lt;td&gt;&lt;strong&gt;17&lt;/strong&gt;&lt;/td&gt;\n&lt;td&gt;Yes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Any help will be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s4vt", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11vyzjk", "is_robot_indexable": true, "report_reasons": null, "author": "hal_leuco", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rprogramming/comments/11vyzjk/using_second_dataframe_as_lookup_to_fill_na_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rprogramming/comments/11vyzjk/using_second_dataframe_as_lookup_to_fill_na_rows/", "subreddit_subscribers": 18466, "created_utc": 1679262727.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679262772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rprogramming", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/rprogramming/comments/11vyzjk/using_second_dataframe_as_lookup_to_fill_na_rows/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11vz0ao", "is_robot_indexable": true, "report_reasons": null, "author": "hal_leuco", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11vyzjk", "author_flair_text_color": "dark", "permalink": "/r/rstats/comments/11vz0ao/using_second_dataframe_as_lookup_to_fill_na_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rprogramming/comments/11vyzjk/using_second_dataframe_as_lookup_to_fill_na_rows/", "subreddit_subscribers": 71012, "created_utc": 1679262772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "rstats", "selftext": "Im just a student researcher and I have a bunch of data from my results. 120 responses to be exact. I\u2019ve been trying to teach myself how to analyze data but nothing is helpful. I have no idea what code is or java or python or projects. I have a very small background in statistics but it\u2019s basic stuff. Will someone direct me to a website I can use that makes sense? I\u2019d be happy to attach a link to my sheet if anyone wants to look at it themselves\n\ni\u2019m fascinated that anyone could ever understand the small stuff i saw today. you guys are crazy smart!!", "author_fullname": "t2_kjpxxc6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019ve never been so confused", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11w8jnl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679286699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im just a student researcher and I have a bunch of data from my results. 120 responses to be exact. I\u2019ve been trying to teach myself how to analyze data but nothing is helpful. I have no idea what code is or java or python or projects. I have a very small background in statistics but it\u2019s basic stuff. Will someone direct me to a website I can use that makes sense? I\u2019d be happy to attach a link to my sheet if anyone wants to look at it themselves&lt;/p&gt;\n\n&lt;p&gt;i\u2019m fascinated that anyone could ever understand the small stuff i saw today. you guys are crazy smart!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11w8jnl", "is_robot_indexable": true, "report_reasons": null, "author": "CryptographerRare149", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/11w8jnl/ive_never_been_so_confused/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/rstats/comments/11w8jnl/ive_never_been_so_confused/", "subreddit_subscribers": 71012, "created_utc": 1679286699.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}